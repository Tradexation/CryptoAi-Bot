# main.py - The FINAL, fully optimized structure for Render Web Service

import os
import ccxt
import pandas as pd
import numpy as np
import asyncio
from datetime import datetime, timedelta
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from telegram import Bot
from flask import Flask, jsonify, render_template_string
import threading
import time
import traceback 

# --- ML Imports ---
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split 
from sklearn.preprocessing import StandardScaler 

# --- CONFIGURATION LOADING ---
from dotenv import load_dotenv 
load_dotenv() 

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
CRYPTOS = os.getenv("CRYPTOS", "BTC/USDT,ETH/USDT").split(',') 
TIMEFRAME = os.getenv("TIMEFRAME", "4h")
DAILY_TIMEFRAME = '1d' 
ANALYSIS_INTERVAL = 30 

# Initialize Bot and Exchange
bot = Bot(token=TELEGRAM_BOT_TOKEN)
exchange = ccxt.kraken({
    'enableRateLimit': True,
    'rateLimit': 1000, 
})

# Global ML Model and Scaler (must be global for prediction)
ML_MODEL = None
SCALER = None

# ========== FLASK WEB SERVER & STATUS TRACKING ==========
app = Flask(__name__) 

bot_stats = {
    "status": "initializing",
    "total_analyses": 0,
    "last_analysis": None,
    "monitored_assets": CRYPTOS,
    "uptime_start": datetime.now().isoformat()
}

@app.route('/')
def home():
    return render_template_string("<h1>Bot Status Page</h1>" + 
                                 f"<p>Status: {bot_stats['status']}</p>" + 
                                 f"<p>Analyses: {bot_stats['total_analyses']}</p>" +
                                 f"<p>Last Analysis: {bot_stats['last_analysis'] or 'N/A'}</p>")

@app.route('/health')
def health():
    return jsonify({"status": "healthy", "timestamp": datetime.now().isoformat()}), 200

@app.route('/status')
def status():
    return jsonify(bot_stats), 200

# ========== ML TRAINING FUNCTION ==========

def train_prediction_model(df):
    """Trains a Logistic Regression model and returns the model and scaler."""
    global SCALER
    
    try:
        if len(df) < 100:
            print(f"‚ö†Ô∏è Not enough data ({len(df)} rows, need 100+) for ML training. Skipping.")
            return None, None

        # 1. Target Definition (y) - Predict if next close is higher
        df['target'] = np.where(df['close'].shift(-1) > df['close'], 1, 0)
        
        # 2. Feature Engineering (X)
        df['fast_over_slow'] = np.where(df['fast_sma'] > df['slow_sma'], 1, 0)
        df['close_over_fast'] = np.where(df['close'] > df['fast_sma'], 1, 0)
        
        # Volatility calculation with safety checks
        returns = df['close'].pct_change()
        df['volatility'] = returns.rolling(20, min_periods=1).std().fillna(0)
        
        # Replace inf and extreme values
        df['volatility'] = df['volatility'].replace([np.inf, -np.inf], 0)
        df['volatility'] = np.clip(df['volatility'], 0, 1)  # Cap at 100%
        
        # Drop NaN rows
        df = df.dropna()
        
        if len(df) < 50:
            print(f"‚ö†Ô∏è After cleaning, only {len(df)} rows left. Need 50+. Skipping ML.")
            return None, None
        
        # Features and target
        X = df[['fast_over_slow', 'close_over_fast', 'volatility']].copy()
        y = df['target'].copy()
        
        # Use 90% for training
        split_idx = int(len(X) * 0.9)
        X_train = X.iloc[:split_idx]
        y_train = y.iloc[:split_idx]

        # 3. Scaling
        SCALER = StandardScaler()
        X_train_scaled = SCALER.fit_transform(X_train)

        # 4. Training
        model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)
        model.fit(X_train_scaled, y_train)
        
        accuracy = model.score(X_train_scaled, y_train)
        print(f"‚úÖ ML Model trained successfully. Training Accuracy: {accuracy:.2%}")
        return model, SCALER
        
    except Exception as e:
        print(f"‚ùå ML Training Error: {e}")
        traceback.print_exc()
        return None, None

# ========== TECHNICAL ANALYSIS FUNCTIONS ==========

# 1. CPR Calculation Function
def calculate_cpr_levels(df_daily):
    """Calculates Daily Pivot Points (PP, TC, BC, R/S levels) from previous day's data."""
    if df_daily.empty or len(df_daily) < 2:
        return None

    prev_day = df_daily.iloc[-2]  
    H, L, C = prev_day['high'], prev_day['low'], prev_day['close']
    
    PP = (H + L + C) / 3.0
    BC = (H + L) / 2.0
    TC = PP - BC + PP
    
    R1 = 2 * PP - L
    S1 = 2 * PP - H
    R2 = PP + (H - L)
    S2 = PP - (H - L)
    R3 = H + 2 * (PP - L)
    S3 = L - 2 * (H - PP)
    
    return {'PP': PP, 'TC': TC, 'BC': BC, 'R1': R1, 'S1': S1,
            'R2': R2, 'S2': S2, 'R3': R3, 'S3': S3}

# 2. Data Fetching and Preparation Function
def fetch_and_prepare_data(symbol, timeframe, daily_timeframe='1d', limit=500):
    """Fetches main chart data, prepares for analysis, and calculates SMAs."""
    
    ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)
    df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    df.set_index('timestamp', inplace=True)
    df = df.dropna()
    
    df['fast_sma'] = df['close'].rolling(window=9).mean()
    df['slow_sma'] = df['close'].rolling(window=20).mean()
    
    df = df.dropna() 
    
    if len(df) < 20: 
        return pd.DataFrame(), None
    
    ohlcv_daily = exchange.fetch_ohlcv(symbol, daily_timeframe, limit=20) 
    df_daily = pd.DataFrame(ohlcv_daily, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
    df_daily.set_index('timestamp', inplace=True)
    
    cpr_levels = calculate_cpr_levels(df_daily)
    
    return df, cpr_levels

# 3. Trend and Signal Generation
def get_trend_and_signal(df, cpr_levels):
    """Determines trend via SMA crossover and incorporates ML prediction."""
    
    latest = df.iloc[-1]
    current_price = latest['close']
    fast_sma = latest['fast_sma']
    slow_sma = latest['slow_sma']
    
    # --- ML Prediction Block ---
    ml_prediction = "NEUTRAL (No Model)"
    ml_confidence = "N/A"
    
    if ML_MODEL is not None and SCALER is not None:
        try:
            # 1. Calculate volatility safely
            if len(df) >= 20:
                close_prices_recent = df['close'].iloc[-20:]
                returns = close_prices_recent.pct_change().dropna()
                
                if len(returns) > 0:
                    current_volatility = float(returns.std())
                    # Safety checks
                    if np.isnan(current_volatility) or np.isinf(current_volatility):
                        current_volatility = 0.0
                    current_volatility = np.clip(current_volatility, 0, 1)  # Cap at 100%
                else:
                    current_volatility = 0.0
            else:
                current_volatility = 0.0

            # 2. Build the latest features DataFrame
            is_fast_over_slow = 1 if fast_sma > slow_sma else 0
            is_close_over_fast = 1 if current_price > fast_sma else 0
            
            latest_features = pd.DataFrame({
                'fast_over_slow': [is_fast_over_slow],
                'close_over_fast': [is_close_over_fast],
                'volatility': [current_volatility] 
            })
            
            # 3. Scaling and Prediction
            X_predict_scaled = SCALER.transform(latest_features)
            prediction = ML_MODEL.predict(X_predict_scaled)[0]
            probability = ML_MODEL.predict_proba(X_predict_scaled)[0]
            bullish_prob = probability[1]
            bearish_prob = probability[0]
            
            # 4. Final Prediction Output
            if prediction == 1 and bullish_prob > 0.55:
                ml_prediction = "BULLISH"
                ml_confidence = f"{bullish_prob*100:.0f}%"
            elif prediction == 0 and bearish_prob > 0.55:
                ml_prediction = "BEARISH"
                ml_confidence = f"{bearish_prob*100:.0f}%"
            else:
                ml_prediction = "NEUTRAL"
                ml_confidence = f"{max(bullish_prob, bearish_prob)*100:.0f}%"

        except Exception as e:
            print(f"‚ùå ML PREDICTION FAILED: {e}")
            traceback.print_exc()
            ml_prediction = "NEUTRAL (Error)"
            ml_confidence = "Error"
            
    # --- End of ML Prediction Block ---

    # --- Trend Assessment ---
    trend = "Neutral"
    if fast_sma > slow_sma:
        trend = "Uptrend"
        trend_emoji = "üü¢"
    elif fast_sma < slow_sma:
        trend = "Downtrend"
        trend_emoji = "üî¥"
    else:
        trend_emoji = "üü°"

    # --- Final Signal Generation ---
    pp = cpr_levels.get('PP', 'N/A')
    
    proximity_msg = ""
    if pp != 'N/A':
        distance_to_pp = current_price - pp
        if abs(distance_to_pp / pp) < 0.005: 
            proximity_msg = "Price is near the Central Pivot Point (PP)."
        elif distance_to_pp > 0:
            proximity_msg = f"Price is Above PP ({pp:.2f})."
        else:
            proximity_msg = f"Price is Below PP ({pp:.2f})."
            
    signal = "HOLD"
    signal_emoji = "üü°"
    if "BULLISH" in ml_prediction and current_price > pp:
        signal = "STRONG BUY"
        signal_emoji = "üöÄ"
    elif "BEARISH" in ml_prediction and current_price < pp:
        signal = "STRONG SELL"
        signal_emoji = "üîª"
        
    return trend, trend_emoji, proximity_msg, signal, signal_emoji, ml_prediction, ml_confidence

# 4. ASYNC SCHEDULER FUNCTIONS

async def generate_and_send_signal(symbol):
    """Fetches data, runs analysis, and sends the Telegram message."""
    
    try:
        print(f"\n{'='*60}")
        print(f"üîç Analyzing {symbol}...")
        
        # Step 1: Fetch and Prepare Data
        df, cpr_levels = fetch_and_prepare_data(symbol, TIMEFRAME)
        
        if df.empty or cpr_levels is None:
            message = f"üö® Data Fetch/Processing Error for {symbol}. Could not generate signal (Insufficient clean data)."
            await bot.send_message(chat_id=TELEGRAM_CHAT_ID, text=message)
            return

        # Step 2: Generate Analysis & Signal
        trend, trend_emoji, proximity_msg, signal, signal_emoji, ml_prediction, ml_confidence = get_trend_and_signal(df, cpr_levels)
        current_price = df.iloc[-1]['close']
        
        cpr_text = (
            f"<b>Daily CPR Levels:</b>\n"
            f"  - <b>PP (Pivot Point):</b> <code>{cpr_levels['PP']:.2f}</code>\n"
            f"  - <b>R1/S1:</b> <code>{cpr_levels['R1']:.2f}</code> / <code>{cpr_levels['S1']:.2f}</code>\n"
            f"  - <b>R2/S2:</b> <code>{cpr_levels['R2']:.2f}</code> / <code>{cpr_levels['S2']:.2f}</code>\n"
        )
        
        # --- FINAL PROFESSIONAL HTML MESSAGE TEMPLATE ---
        message = (
            f"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n"
            f"  üß† <b>AI MARKET INTELLIGENCE REPORT</b>\n"
            f"‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n\n"
            
            f"<b>{symbol}</b> | {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}\n\n"
            
            f"---üö® <b>{signal_emoji} FINAL SIGNAL: {signal}</b> üö®---\n\n"
            
            f"<b>üí∞ Current Price:</b> <code>{current_price:,.2f}</code>\n"
            f"<b>‚è∞ Timeframe:</b> {TIMEFRAME}\n"
            
            f"\n<b>ü§ñ ML PREDICTION</b>\n"
            f"<b>Forecast:</b> {ml_prediction}\n"
            f"<b>Confidence:</b> {ml_confidence}\n"
            
            f"\n<b>üìä TECHNICAL &amp; KEY LEVELS</b>\n"
            f"{trend_emoji} <b>Trend (SMA 9/20):</b> {trend}\n"
            f"{proximity_msg}\n\n"
            
            f"{cpr_text}\n"
            
            f"----------------------------------------\n"
            f"<i>Disclaimer: This analysis is for educational purposes only.</i>"
        )

        await bot.send_message(chat_id=TELEGRAM_CHAT_ID, text=message, parse_mode='HTML')
        
        bot_stats['total_analyses'] += 1
        bot_stats['last_analysis'] = datetime.now().isoformat()
        bot_stats['status'] = "operational"
        
        print(f"‚úÖ Analysis sent: {symbol} | Signal: {signal} | ML: {ml_prediction} ({ml_confidence})")

    except Exception as e:
        error_trace = traceback.format_exc()
        print(f"‚ùå Error generating signal for {symbol}: {e}")
        print(error_trace)
        
        diagnostic_message = (
            f"‚ùå <b>FATAL ANALYSIS ERROR for {symbol}</b> ‚ùå\n\n"
            f"<b>Time:</b> {datetime.now().strftime('%H:%M:%S UTC')}\n"
            f"<b>Issue:</b> The calculation thread crashed.\n\n"
            f"<b>Error:</b> <code>{str(e)[:200]}</code>"
        )
        await bot.send_message(chat_id=TELEGRAM_CHAT_ID, text=diagnostic_message, parse_mode='HTML')


async def start_scheduler_loop():
    """Sets up the scheduler and keeps the asyncio loop running."""
    
    # --- ML Training before starting the loop ---
    global ML_MODEL
    global SCALER

    print("\n‚è≥ Preparing and training Machine Learning Model...")
    try:
        # Fetch more data for better training
        ohlcv_train = exchange.fetch_ohlcv(CRYPTOS[0].strip(), TIMEFRAME, limit=600)
        df_train = pd.DataFrame(ohlcv_train, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df_train['close'] = pd.to_numeric(df_train['close'])
        
        df_train['fast_sma'] = df_train['close'].rolling(window=9).mean()
        df_train['slow_sma'] = df_train['close'].rolling(window=20).mean()
        df_train = df_train.dropna()
        
        ML_MODEL, SCALER = train_prediction_model(df_train)
        
        if ML_MODEL is None:
            print("‚ö†Ô∏è Bot will run WITHOUT ML predictions (using technical analysis only)")
        
    except Exception as e:
        print(f"‚ùå ML Model Training Failed: {e}")
        traceback.print_exc()
        ML_MODEL = None
        SCALER = None

    # --- Start the scheduler loop ---
    scheduler = AsyncIOScheduler()
    
    for symbol in [s.strip() for s in CRYPTOS]:
        scheduler.add_job(generate_and_send_signal, 'cron', minute='0,30', args=[symbol]) 
    
    scheduler.start()
    print("üöÄ Scheduler started successfully. Signals every 30 minutes.")

    # Run initial analysis immediately
    for symbol in [s.strip() for s in CRYPTOS]:
        await generate_and_send_signal(symbol)
        await asyncio.sleep(5)  # Small delay between symbols

    # Keep the main thread running
    while True:
        await asyncio.sleep(60)


# 5. CRITICAL STARTUP THREAD

def start_asyncio_thread():
    """Target function for the background thread."""
    try:
        asyncio.run(start_scheduler_loop())
    except Exception as e:
        print(f"FATAL SCHEDULER ERROR: {e}")
        traceback.print_exc()

# This thread starts immediately when Gunicorn loads the 'app' instance
scheduler_thread = threading.Thread(target=start_asyncio_thread, daemon=True)
scheduler_thread.start()

print("‚úÖ Gunicorn loading Flask app. Scheduler thread initialized.")
